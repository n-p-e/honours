[
  {
    "dataset": "dataset/realworld/graph_ia-infect-dublin",
    "algo": "v2",
    "n": 410,
    "m": 2765,
    "runtime_ms": 0.411,
    "improved_solution": false,
    "initial_size": 16,
    "solution_size": 16,
    "exact_size": 17,
    "exact_runtime_ms": 0.152
  },
  {
    "dataset": "dataset/realworld/graph_ia-enron-only",
    "algo": "v2",
    "n": 143,
    "m": 623,
    "runtime_ms": 0.148,
    "improved_solution": false,
    "initial_size": 8,
    "solution_size": 8,
    "exact_size": 10,
    "exact_runtime_ms": 0.06
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_qatif",
    "algo": "v2",
    "n": 14,
    "m": 11,
    "runtime_ms": 0.009,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 3,
    "exact_runtime_ms": 0.005
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_lolgop",
    "algo": "v2",
    "n": 273,
    "m": 4510,
    "runtime_ms": 0.523,
    "improved_solution": false,
    "initial_size": 42,
    "solution_size": 42,
    "exact_size": 43,
    "exact_runtime_ms": 0.345
  },
  {
    "dataset": "dataset/realworld/graph_ca-GrQc",
    "algo": "v2",
    "n": 4158,
    "m": 13422,
    "runtime_ms": 1.067,
    "improved_solution": false,
    "initial_size": 44,
    "solution_size": 44,
    "exact_size": 44,
    "exact_runtime_ms": 0.203
  },
  {
    "dataset": "dataset/realworld/graph_ca-HepPh",
    "algo": "v2",
    "n": 11204,
    "m": 117619,
    "runtime_ms": 8.969,
    "improved_solution": false,
    "initial_size": 239,
    "solution_size": 239,
    "exact_size": 239,
    "exact_runtime_ms": 2.141
  },
  {
    "dataset": "dataset/realworld/graph_ia-enron-large",
    "algo": "v2",
    "n": 33696,
    "m": 180811,
    "runtime_ms": 107.588,
    "improved_solution": true,
    "initial_size": 16,
    "solution_size": 19,
    "exact_size": 22,
    "exact_runtime_ms": 36.28
  },
  {
    "dataset": "dataset/realworld/graph_soc-slashdot",
    "algo": "v2",
    "n": 70068,
    "m": 358647,
    "runtime_ms": 224.624,
    "improved_solution": false,
    "initial_size": 25,
    "solution_size": 25,
    "exact_size": 31,
    "exact_runtime_ms": 212.264
  },
  {
    "dataset": "dataset/realworld/graph_tech-p2p-gnutella",
    "algo": "v2",
    "n": 62561,
    "m": 147878,
    "runtime_ms": 1668.123,
    "improved_solution": true,
    "initial_size": 2,
    "solution_size": 4,
    "exact_size": 5,
    "exact_runtime_ms": 12.483
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_mittromney",
    "algo": "v2",
    "n": 102,
    "m": 108,
    "runtime_ms": 0.033,
    "improved_solution": false,
    "initial_size": 5,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.014
  },
  {
    "dataset": "dataset/realworld/graph_web-BerkStan",
    "algo": "v2",
    "n": 12305,
    "m": 19500,
    "runtime_ms": 1.876,
    "improved_solution": false,
    "initial_size": 29,
    "solution_size": 29,
    "exact_size": 29,
    "exact_runtime_ms": 0.275
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_occupy",
    "algo": "v2",
    "n": 55,
    "m": 60,
    "runtime_ms": 0.02,
    "improved_solution": false,
    "initial_size": 5,
    "solution_size": 5,
    "exact_size": 5,
    "exact_runtime_ms": 0.02
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_damascus",
    "algo": "v2",
    "n": 34,
    "m": 41,
    "runtime_ms": 0.015,
    "improved_solution": false,
    "initial_size": 5,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.009
  },
  {
    "dataset": "dataset/realworld/graph_scc_infect-hyper",
    "algo": "v2",
    "n": 113,
    "m": 6222,
    "runtime_ms": 0.271,
    "improved_solution": false,
    "initial_size": 106,
    "solution_size": 106,
    "exact_size": 106,
    "exact_runtime_ms": 0.405
  },
  {
    "dataset": "dataset/realworld/graph_soc-epinions",
    "algo": "v2",
    "n": 26588,
    "m": 100120,
    "runtime_ms": 70.82,
    "improved_solution": true,
    "initial_size": 12,
    "solution_size": 16,
    "exact_size": 18,
    "exact_runtime_ms": 14.601
  },
  {
    "dataset": "dataset/realworld/graph_tech-as-caida2007",
    "algo": "v2",
    "n": 26475,
    "m": 53381,
    "runtime_ms": 13.757,
    "improved_solution": false,
    "initial_size": 16,
    "solution_size": 16,
    "exact_size": 17,
    "exact_runtime_ms": 1.698
  },
  {
    "dataset": "dataset/realworld/graph_sc-nasasrb",
    "algo": "v2",
    "n": 54870,
    "m": 1311227,
    "runtime_ms": 1596.531,
    "improved_solution": false,
    "initial_size": 24,
    "solution_size": 24,
    "exact_size": 24,
    "exact_runtime_ms": 222.788
  },
  {
    "dataset": "dataset/realworld/graph_rec-amazon",
    "algo": "v2",
    "n": 91813,
    "m": 125704,
    "runtime_ms": 2465.218,
    "improved_solution": true,
    "initial_size": 4,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 2.958
  },
  {
    "dataset": "dataset/realworld/graph_web-google",
    "algo": "v2",
    "n": 1299,
    "m": 2773,
    "runtime_ms": 0.272,
    "improved_solution": false,
    "initial_size": 18,
    "solution_size": 18,
    "exact_size": 19,
    "exact_runtime_ms": 0.061
  },
  {
    "dataset": "dataset/realworld/graph_scc_retweet-crawl",
    "algo": "v2",
    "n": 17151,
    "m": 24015,
    "runtime_ms": 4.219,
    "improved_solution": false,
    "initial_size": 20,
    "solution_size": 20,
    "exact_size": 21,
    "exact_runtime_ms": 0.376
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_israel",
    "algo": "v2",
    "n": 22,
    "m": 12,
    "runtime_ms": 0.014,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 3,
    "exact_runtime_ms": 0.014
  },
  {
    "dataset": "dataset/realworld/graph_ca-CSphd",
    "algo": "v2",
    "n": 1882,
    "m": 1740,
    "runtime_ms": 1.78,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 4,
    "exact_runtime_ms": 0.041
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Texas84",
    "algo": "v2",
    "n": 36364,
    "m": 1590651,
    "runtime_ms": 1012.242,
    "improved_solution": true,
    "initial_size": 48,
    "solution_size": 50,
    "exact_size": 55,
    "exact_runtime_ms": 1387.168
  },
  {
    "dataset": "dataset/realworld/graph_soc-douban",
    "algo": "v2",
    "n": 154908,
    "m": 327162,
    "runtime_ms": 1872.985,
    "improved_solution": true,
    "initial_size": 5,
    "solution_size": 11,
    "exact_size": 12,
    "exact_runtime_ms": 24.839
  },
  {
    "dataset": "dataset/realworld/graph_tech-RL-caida",
    "algo": "v2",
    "n": 190914,
    "m": 607610,
    "runtime_ms": 6515.052,
    "improved_solution": true,
    "initial_size": 6,
    "solution_size": 17,
    "exact_size": 20,
    "exact_runtime_ms": 27.07
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_obama",
    "algo": "v2",
    "n": 8,
    "m": 4,
    "runtime_ms": 0.008,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 2,
    "exact_runtime_ms": 0.01
  },
  {
    "dataset": "dataset/realworld/graph_socfb-UCSB37",
    "algo": "v2",
    "n": 14917,
    "m": 482215,
    "runtime_ms": 185.308,
    "improved_solution": true,
    "initial_size": 52,
    "solution_size": 53,
    "exact_size": 59,
    "exact_runtime_ms": 54.002
  },
  {
    "dataset": "dataset/realworld/graph_sc-shipsec5",
    "algo": "v2",
    "n": 179104,
    "m": 2200076,
    "runtime_ms": 7222.356,
    "improved_solution": false,
    "initial_size": 24,
    "solution_size": 24,
    "exact_size": 24,
    "exact_runtime_ms": 96.884
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_tcot",
    "algo": "v2",
    "n": 26,
    "m": 18,
    "runtime_ms": 0.015,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 4,
    "exact_runtime_ms": 0.007
  },
  {
    "dataset": "dataset/realworld/graph_soc-youtube",
    "algo": "v2",
    "n": 495957,
    "m": 1936748,
    "runtime_ms": 20967.244,
    "improved_solution": true,
    "initial_size": 13,
    "solution_size": 16,
    "exact_size": 20,
    "exact_runtime_ms": 368.19
  },
  {
    "dataset": "dataset/realworld/graph_web-arabic-2005",
    "algo": "v2",
    "n": 163598,
    "m": 1747269,
    "runtime_ms": 53.059,
    "improved_solution": false,
    "initial_size": 102,
    "solution_size": 102,
    "exact_size": 102,
    "exact_runtime_ms": 4.41
  },
  {
    "dataset": "dataset/realworld/graph_ca-dblp-2012",
    "algo": "v2",
    "n": 317080,
    "m": 1049866,
    "runtime_ms": 203.128,
    "improved_solution": false,
    "initial_size": 114,
    "solution_size": 114,
    "exact_size": 114,
    "exact_runtime_ms": 7.702
  },
  {
    "dataset": "dataset/realworld/graph_web-polblogs",
    "algo": "v2",
    "n": 643,
    "m": 2280,
    "runtime_ms": 0.596,
    "improved_solution": false,
    "initial_size": 9,
    "solution_size": 9,
    "exact_size": 12,
    "exact_runtime_ms": 0.164
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_alwefaq",
    "algo": "v2",
    "n": 72,
    "m": 355,
    "runtime_ms": 0.063,
    "improved_solution": false,
    "initial_size": 16,
    "solution_size": 16,
    "exact_size": 17,
    "exact_runtime_ms": 0.041
  },
  {
    "dataset": "dataset/realworld/graph_tech-routers-rf",
    "algo": "v2",
    "n": 2113,
    "m": 6632,
    "runtime_ms": 1.508,
    "improved_solution": false,
    "initial_size": 16,
    "solution_size": 16,
    "exact_size": 17,
    "exact_runtime_ms": 0.246
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_gop",
    "algo": "v2",
    "n": 13,
    "m": 7,
    "runtime_ms": 0.01,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 3,
    "exact_runtime_ms": 0.014
  },
  {
    "dataset": "dataset/realworld/graph_ia-email-univ",
    "algo": "v2",
    "n": 1133,
    "m": 5451,
    "runtime_ms": 0.996,
    "improved_solution": false,
    "initial_size": 12,
    "solution_size": 12,
    "exact_size": 12,
    "exact_runtime_ms": 0.112
  },
  {
    "dataset": "dataset/realworld/graph_soc-LiveMocha",
    "algo": "v2",
    "n": 104103,
    "m": 2193083,
    "runtime_ms": 4884.61,
    "improved_solution": true,
    "initial_size": 6,
    "solution_size": 15,
    "exact_size": 19,
    "exact_runtime_ms": 23832.998
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_assad",
    "algo": "v2",
    "n": 34,
    "m": 96,
    "runtime_ms": 0.054,
    "improved_solution": false,
    "initial_size": 8,
    "solution_size": 8,
    "exact_size": 9,
    "exact_runtime_ms": 0.014
  },
  {
    "dataset": "dataset/realworld/graph_sc-pkustk11",
    "algo": "v2",
    "n": 87804,
    "m": 2565054,
    "runtime_ms": 4290.902,
    "improved_solution": true,
    "initial_size": 24,
    "solution_size": 36,
    "exact_size": 36,
    "exact_runtime_ms": 692.241
  },
  {
    "dataset": "dataset/realworld/graph_ca-AstroPh",
    "algo": "v2",
    "n": 17903,
    "m": 196972,
    "runtime_ms": 30.381,
    "improved_solution": false,
    "initial_size": 57,
    "solution_size": 57,
    "exact_size": 57,
    "exact_runtime_ms": 2.108
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Wisconsin87",
    "algo": "v2",
    "n": 23831,
    "m": 835946,
    "runtime_ms": 566.462,
    "improved_solution": true,
    "initial_size": 34,
    "solution_size": 37,
    "exact_size": 42,
    "exact_runtime_ms": 500.351
  },
  {
    "dataset": "dataset/realworld/graph_soc-FourSquare",
    "algo": "v2",
    "n": 639014,
    "m": 3214986,
    "runtime_ms": 29864.929,
    "improved_solution": true,
    "initial_size": 26,
    "solution_size": 29,
    "exact_size": 35,
    "exact_runtime_ms": 6771.437
  },
  {
    "dataset": "dataset/realworld/graph_ca-hollywood-2009",
    "algo": "v2",
    "n": 1069126,
    "m": 56306653,
    "runtime_ms": 7264.38,
    "improved_solution": false,
    "initial_size": 2209,
    "solution_size": 2209,
    "exact_size": 2209,
    "exact_runtime_ms": 352.778
  },
  {
    "dataset": "dataset/realworld/graph_tech-WHOIS",
    "algo": "v2",
    "n": 7476,
    "m": 56943,
    "runtime_ms": 21.997,
    "improved_solution": true,
    "initial_size": 55,
    "solution_size": 58,
    "exact_size": 64,
    "exact_runtime_ms": 335.408
  },
  {
    "dataset": "dataset/realworld/graph_soc-karate",
    "algo": "v2",
    "n": 34,
    "m": 78,
    "runtime_ms": 0.023,
    "improved_solution": false,
    "initial_size": 5,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.013
  },
  {
    "dataset": "dataset/realworld/graph_bio-dmela",
    "algo": "v2",
    "n": 7393,
    "m": 25569,
    "runtime_ms": 18.547,
    "improved_solution": true,
    "initial_size": 5,
    "solution_size": 7,
    "exact_size": 8,
    "exact_runtime_ms": 2.072
  },
  {
    "dataset": "dataset/realworld/graph_tech-internet-as",
    "algo": "v2",
    "n": 40164,
    "m": 85123,
    "runtime_ms": 35.311,
    "improved_solution": true,
    "initial_size": 14,
    "solution_size": 16,
    "exact_size": 18,
    "exact_runtime_ms": 2.85
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_lebanon",
    "algo": "v2",
    "n": 10,
    "m": 5,
    "runtime_ms": 0.01,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 2,
    "exact_runtime_ms": 0.011
  },
  {
    "dataset": "dataset/realworld/graph_scc_fb-messages",
    "algo": "v2",
    "n": 1303,
    "m": 531893,
    "runtime_ms": 147.5,
    "improved_solution": false,
    "initial_size": 707,
    "solution_size": 707,
    "exact_size": 708,
    "exact_runtime_ms": 36.461
  },
  {
    "dataset": "dataset/realworld/graph_soc-delicious",
    "algo": "v2",
    "n": 536108,
    "m": 1365961,
    "runtime_ms": 13372.023,
    "improved_solution": true,
    "initial_size": 16,
    "solution_size": 21,
    "exact_size": 23,
    "exact_runtime_ms": 54.665
  },
  {
    "dataset": "dataset/realworld/graph_bio-yeast",
    "algo": "v2",
    "n": 1458,
    "m": 1948,
    "runtime_ms": 0.893,
    "improved_solution": false,
    "initial_size": 6,
    "solution_size": 6,
    "exact_size": 6,
    "exact_runtime_ms": 0.049
  },
  {
    "dataset": "dataset/realworld/graph_scc_retweet",
    "algo": "v2",
    "n": 1206,
    "m": 65990,
    "runtime_ms": 20.633,
    "improved_solution": true,
    "initial_size": 164,
    "solution_size": 166,
    "exact_size": 166,
    "exact_runtime_ms": 30.031
  },
  {
    "dataset": "dataset/realworld/graph_soc-brightkite",
    "algo": "v2",
    "n": 56739,
    "m": 212945,
    "runtime_ms": 79.319,
    "improved_solution": false,
    "initial_size": 37,
    "solution_size": 37,
    "exact_size": 44,
    "exact_runtime_ms": 7.674
  },
  {
    "dataset": "dataset/realworld/graph_sc-pwtk",
    "algo": "v2",
    "n": 217891,
    "m": 5653221,
    "runtime_ms": 25404.147,
    "improved_solution": false,
    "initial_size": 24,
    "solution_size": 24,
    "exact_size": 24,
    "exact_runtime_ms": 957.841
  },
  {
    "dataset": "dataset/realworld/graph_socfb-UCLA",
    "algo": "v2",
    "n": 20453,
    "m": 747604,
    "runtime_ms": 451.163,
    "improved_solution": false,
    "initial_size": 50,
    "solution_size": 50,
    "exact_size": 55,
    "exact_runtime_ms": 407.491
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_uae",
    "algo": "v2",
    "n": 18,
    "m": 12,
    "runtime_ms": 0.012,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 3,
    "exact_runtime_ms": 0.006
  },
  {
    "dataset": "dataset/realworld/graph_ca-MathSciNet",
    "algo": "v2",
    "n": 332689,
    "m": 820644,
    "runtime_ms": 1441.496,
    "improved_solution": false,
    "initial_size": 25,
    "solution_size": 25,
    "exact_size": 25,
    "exact_runtime_ms": 10.936
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_ksa",
    "algo": "v2",
    "n": 21,
    "m": 23,
    "runtime_ms": 0.012,
    "improved_solution": false,
    "initial_size": 6,
    "solution_size": 6,
    "exact_size": 6,
    "exact_runtime_ms": 0.006
  },
  {
    "dataset": "dataset/realworld/graph_tech-as-skitter",
    "algo": "v2",
    "n": 1694616,
    "m": 11094209,
    "runtime_ms": 50542.583,
    "improved_solution": true,
    "initial_size": 57,
    "solution_size": 67,
    "exact_size": 69,
    "exact_runtime_ms": 526.001
  },
  {
    "dataset": "dataset/realworld/graph_soc-twitter-follows",
    "algo": "v2",
    "n": 404719,
    "m": 713319,
    "runtime_ms": 147711.959,
    "improved_solution": true,
    "initial_size": 2,
    "solution_size": 6,
    "exact_size": 8,
    "exact_runtime_ms": 77.463
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_dash",
    "algo": "v2",
    "n": 31,
    "m": 39,
    "runtime_ms": 0.013,
    "improved_solution": false,
    "initial_size": 6,
    "solution_size": 6,
    "exact_size": 6,
    "exact_runtime_ms": 0.009
  },
  {
    "dataset": "dataset/realworld/graph_socfb-UF",
    "algo": "v2",
    "n": 35111,
    "m": 1465654,
    "runtime_ms": 1283.077,
    "improved_solution": true,
    "initial_size": 47,
    "solution_size": 55,
    "exact_size": 60,
    "exact_runtime_ms": 1750.566
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_p2",
    "algo": "v2",
    "n": 26,
    "m": 15,
    "runtime_ms": 0.02,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 3,
    "exact_runtime_ms": 0.016
  },
  {
    "dataset": "dataset/realworld/graph_socfb-UIllinois",
    "algo": "v2",
    "n": 30795,
    "m": 1264421,
    "runtime_ms": 1343.475,
    "improved_solution": true,
    "initial_size": 18,
    "solution_size": 57,
    "exact_size": 63,
    "exact_runtime_ms": 1369.757
  },
  {
    "dataset": "dataset/realworld/graph_soc-lastfm",
    "algo": "v2",
    "n": 1191805,
    "m": 4519330,
    "runtime_ms": 118283.572,
    "improved_solution": true,
    "initial_size": 13,
    "solution_size": 14,
    "exact_size": 18,
    "exact_runtime_ms": 16338.907
  },
  {
    "dataset": "dataset/realworld/graph_socfb-UConn",
    "algo": "v2",
    "n": 17206,
    "m": 604867,
    "runtime_ms": 292.413,
    "improved_solution": false,
    "initial_size": 50,
    "solution_size": 50,
    "exact_size": 53,
    "exact_runtime_ms": 180.543
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_http",
    "algo": "v2",
    "n": 5,
    "m": 6,
    "runtime_ms": 0.009,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 4,
    "exact_runtime_ms": 0.005
  },
  {
    "dataset": "dataset/realworld/graph_bio-diseasome",
    "algo": "v2",
    "n": 516,
    "m": 1188,
    "runtime_ms": 0.146,
    "improved_solution": false,
    "initial_size": 11,
    "solution_size": 11,
    "exact_size": 11,
    "exact_runtime_ms": 0.033
  },
  {
    "dataset": "dataset/realworld/graph_soc-dolphins",
    "algo": "v2",
    "n": 62,
    "m": 159,
    "runtime_ms": 0.06,
    "improved_solution": false,
    "initial_size": 5,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.016
  },
  {
    "dataset": "dataset/realworld/graph_soc-livejournal",
    "algo": "v2",
    "n": 4033137,
    "m": 27933062,
    "runtime_ms": 31744.454,
    "improved_solution": false,
    "initial_size": 214,
    "solution_size": 214,
    "exact_size": 214,
    "exact_runtime_ms": 652.96
  },
  {
    "dataset": "dataset/realworld/graph_web-indochina-2004",
    "algo": "v2",
    "n": 11358,
    "m": 47606,
    "runtime_ms": 3.53,
    "improved_solution": false,
    "initial_size": 50,
    "solution_size": 50,
    "exact_size": 50,
    "exact_runtime_ms": 0.382
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Duke14",
    "algo": "v2",
    "n": 9885,
    "m": 506437,
    "runtime_ms": 409.191,
    "improved_solution": true,
    "initial_size": 29,
    "solution_size": 34,
    "exact_size": 38,
    "exact_runtime_ms": 6947.12
  },
  {
    "dataset": "dataset/realworld/graph_ca-Erdos992",
    "algo": "v2",
    "n": 5094,
    "m": 7515,
    "runtime_ms": 2.627,
    "improved_solution": false,
    "initial_size": 8,
    "solution_size": 8,
    "exact_size": 8,
    "exact_runtime_ms": 0.103
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Penn94",
    "algo": "v2",
    "n": 41536,
    "m": 1362220,
    "runtime_ms": 1257.898,
    "improved_solution": true,
    "initial_size": 34,
    "solution_size": 43,
    "exact_size": 50,
    "exact_runtime_ms": 993.555
  },
  {
    "dataset": "dataset/realworld/graph_ca-coauthors-dblp",
    "algo": "v2",
    "n": 540486,
    "m": 15245729,
    "runtime_ms": 2347.796,
    "improved_solution": false,
    "initial_size": 337,
    "solution_size": 337,
    "exact_size": 337,
    "exact_runtime_ms": 40.605
  },
  {
    "dataset": "dataset/realworld/graph_scc_enron-only",
    "algo": "v2",
    "n": 146,
    "m": 9828,
    "runtime_ms": 0.809,
    "improved_solution": false,
    "initial_size": 120,
    "solution_size": 120,
    "exact_size": 121,
    "exact_runtime_ms": 0.752
  },
  {
    "dataset": "dataset/realworld/graph_rt-retweet-crawl",
    "algo": "v2",
    "n": 1112702,
    "m": 2278852,
    "runtime_ms": 84273.024,
    "improved_solution": true,
    "initial_size": 9,
    "solution_size": 13,
    "exact_size": 14,
    "exact_runtime_ms": 175.438
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_barackobama",
    "algo": "v2",
    "n": 80,
    "m": 226,
    "runtime_ms": 0.056,
    "improved_solution": false,
    "initial_size": 10,
    "solution_size": 10,
    "exact_size": 11,
    "exact_runtime_ms": 0.05
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Stanford3",
    "algo": "v2",
    "n": 11586,
    "m": 568309,
    "runtime_ms": 473.53,
    "improved_solution": true,
    "initial_size": 21,
    "solution_size": 51,
    "exact_size": 59,
    "exact_runtime_ms": 600.687
  },
  {
    "dataset": "dataset/realworld/graph_inf-power",
    "algo": "v2",
    "n": 4941,
    "m": 6594,
    "runtime_ms": 2.884,
    "improved_solution": false,
    "initial_size": 6,
    "solution_size": 6,
    "exact_size": 6,
    "exact_runtime_ms": 0.135
  },
  {
    "dataset": "dataset/realworld/graph_inf-roadNet-PA",
    "algo": "v2",
    "n": 1087562,
    "m": 1541514,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_web-wikipedia2009",
    "algo": "v2",
    "n": 1864433,
    "m": 4507315,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_scc_twitter-copen",
    "algo": "v2",
    "n": 2623,
    "m": 473614,
    "runtime_ms": 257.002,
    "improved_solution": true,
    "initial_size": 576,
    "solution_size": 581,
    "exact_size": 581,
    "exact_runtime_ms": 564.565
  },
  {
    "dataset": "dataset/realworld/graph_scc_reality",
    "algo": "v2",
    "n": 6809,
    "m": 4714485,
    "runtime_ms": 1817.229,
    "improved_solution": false,
    "initial_size": 1236,
    "solution_size": 1236,
    "exact_size": 1236,
    "exact_runtime_ms": 269.708
  },
  {
    "dataset": "dataset/realworld/graph_bio-celegans",
    "algo": "v2",
    "n": 453,
    "m": 2025,
    "runtime_ms": 0.441,
    "improved_solution": true,
    "initial_size": 8,
    "solution_size": 9,
    "exact_size": 10,
    "exact_runtime_ms": 0.17
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_justinbieber",
    "algo": "v2",
    "n": 62,
    "m": 442,
    "runtime_ms": 0.073,
    "improved_solution": false,
    "initial_size": 17,
    "solution_size": 17,
    "exact_size": 18,
    "exact_runtime_ms": 0.044
  },
  {
    "dataset": "dataset/realworld/graph_sc-pkustk13",
    "algo": "v2",
    "n": 94893,
    "m": 3260967,
    "runtime_ms": 5353.775,
    "improved_solution": true,
    "initial_size": 33,
    "solution_size": 36,
    "exact_size": 36,
    "exact_runtime_ms": 1118.859
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_oman",
    "algo": "v2",
    "n": 16,
    "m": 13,
    "runtime_ms": 0.016,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 4,
    "exact_runtime_ms": 0.005
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_saudi",
    "algo": "v2",
    "n": 28,
    "m": 91,
    "runtime_ms": 0.031,
    "improved_solution": false,
    "initial_size": 8,
    "solution_size": 8,
    "exact_size": 9,
    "exact_runtime_ms": 0.033
  },
  {
    "dataset": "dataset/realworld/graph_socfb-CMU",
    "algo": "v2",
    "n": 6621,
    "m": 249959,
    "runtime_ms": 170.477,
    "improved_solution": true,
    "initial_size": 35,
    "solution_size": 45,
    "exact_size": 47,
    "exact_runtime_ms": 168.896
  },
  {
    "dataset": "dataset/realworld/graph_sc-shipsec1",
    "algo": "v2",
    "n": 140385,
    "m": 1707759,
    "runtime_ms": 4739.22,
    "improved_solution": false,
    "initial_size": 24,
    "solution_size": 24,
    "exact_size": 24,
    "exact_runtime_ms": 66.669
  },
  {
    "dataset": "dataset/realworld/graph_sc-ldoor",
    "algo": "v2",
    "n": 909537,
    "m": 20770807,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_libya",
    "algo": "v2",
    "n": 27,
    "m": 26,
    "runtime_ms": 0.031,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 4,
    "exact_runtime_ms": 0.015
  },
  {
    "dataset": "dataset/realworld/graph_scc_infect-dublin",
    "algo": "v2",
    "n": 10972,
    "m": 175573,
    "runtime_ms": 24.221,
    "improved_solution": false,
    "initial_size": 84,
    "solution_size": 84,
    "exact_size": 84,
    "exact_runtime_ms": 1.254
  },
  {
    "dataset": "dataset/realworld/graph_ca-dblp-2010",
    "algo": "v2",
    "n": 226413,
    "m": 716460,
    "runtime_ms": 122.589,
    "improved_solution": false,
    "initial_size": 75,
    "solution_size": 75,
    "exact_size": 75,
    "exact_runtime_ms": 5.918
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_voteonedirection",
    "algo": "v2",
    "n": 7,
    "m": 5,
    "runtime_ms": 0.01,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 3,
    "exact_runtime_ms": 0.005
  },
  {
    "dataset": "dataset/realworld/graph_ia-wiki-Talk",
    "algo": "v2",
    "n": 92117,
    "m": 360767,
    "runtime_ms": 586.904,
    "improved_solution": true,
    "initial_size": 11,
    "solution_size": 13,
    "exact_size": 18,
    "exact_runtime_ms": 1730.662
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_onedirection",
    "algo": "v2",
    "n": 35,
    "m": 368,
    "runtime_ms": 0.039,
    "improved_solution": false,
    "initial_size": 27,
    "solution_size": 27,
    "exact_size": 27,
    "exact_runtime_ms": 0.021
  },
  {
    "dataset": "dataset/realworld/graph_socfb-OR",
    "algo": "v2",
    "n": 63392,
    "m": 816886,
    "runtime_ms": 940.583,
    "improved_solution": true,
    "initial_size": 25,
    "solution_size": 30,
    "exact_size": 33,
    "exact_runtime_ms": 327.002
  },
  {
    "dataset": "dataset/realworld/graph_soc-pokec",
    "algo": "v2",
    "n": 1632803,
    "m": 22301964,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_bahrain",
    "algo": "v2",
    "n": 72,
    "m": 129,
    "runtime_ms": 0.039,
    "improved_solution": false,
    "initial_size": 8,
    "solution_size": 8,
    "exact_size": 9,
    "exact_runtime_ms": 0.027
  },
  {
    "dataset": "dataset/realworld/graph_sc-msdoor",
    "algo": "v2",
    "n": 404785,
    "m": 9378650,
    "runtime_ms": 145261.006,
    "improved_solution": false,
    "initial_size": 21,
    "solution_size": 21,
    "exact_size": 21,
    "exact_runtime_ms": 6676.657
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_gmanews",
    "algo": "v2",
    "n": 135,
    "m": 1078,
    "runtime_ms": 0.13,
    "improved_solution": false,
    "initial_size": 22,
    "solution_size": 22,
    "exact_size": 22,
    "exact_runtime_ms": 0.347
  },
  {
    "dataset": "dataset/realworld/graph_rt-twitter-copen",
    "algo": "v2",
    "n": 761,
    "m": 1029,
    "runtime_ms": 0.358,
    "improved_solution": false,
    "initial_size": 4,
    "solution_size": 4,
    "exact_size": 5,
    "exact_runtime_ms": 0.056
  },
  {
    "dataset": "dataset/realworld/graph_ia-fb-messages",
    "algo": "v2",
    "n": 1266,
    "m": 6451,
    "runtime_ms": 2.574,
    "improved_solution": true,
    "initial_size": 4,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.942
  },
  {
    "dataset": "dataset/realworld/graph_web-edu",
    "algo": "v2",
    "n": 3031,
    "m": 6474,
    "runtime_ms": 0.568,
    "improved_solution": false,
    "initial_size": 30,
    "solution_size": 30,
    "exact_size": 30,
    "exact_runtime_ms": 0.071
  },
  {
    "dataset": "dataset/realworld/graph_socfb-A-anon",
    "algo": "v2",
    "n": 3097165,
    "m": 23667394,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_web-sk-2005",
    "algo": "v2",
    "n": 121422,
    "m": 334419,
    "runtime_ms": 40.924,
    "improved_solution": false,
    "initial_size": 82,
    "solution_size": 82,
    "exact_size": 82,
    "exact_runtime_ms": 4.68
  },
  {
    "dataset": "dataset/realworld/graph_ca-citeseer",
    "algo": "v2",
    "n": 227320,
    "m": 814134,
    "runtime_ms": 127.236,
    "improved_solution": false,
    "initial_size": 87,
    "solution_size": 87,
    "exact_size": 87,
    "exact_runtime_ms": 10.633
  },
  {
    "dataset": "dataset/realworld/graph_ia-reality",
    "algo": "v2",
    "n": 6809,
    "m": 7680,
    "runtime_ms": 2.495,
    "improved_solution": true,
    "initial_size": 4,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.163
  },
  {
    "dataset": "dataset/realworld/graph_ia-email-EU",
    "algo": "v2",
    "n": 32430,
    "m": 54397,
    "runtime_ms": 23.962,
    "improved_solution": true,
    "initial_size": 11,
    "solution_size": 12,
    "exact_size": 15,
    "exact_runtime_ms": 3.523
  },
  {
    "dataset": "dataset/realworld/graph_soc-youtube-snap",
    "algo": "v2",
    "n": 1134890,
    "m": 2987624,
    "runtime_ms": 75846.377,
    "improved_solution": true,
    "initial_size": 13,
    "solution_size": 16,
    "exact_size": 20,
    "exact_runtime_ms": 534.74
  },
  {
    "dataset": "dataset/realworld/graph_socfb-MIT",
    "algo": "v2",
    "n": 6402,
    "m": 251230,
    "runtime_ms": 172.939,
    "improved_solution": true,
    "initial_size": 29,
    "solution_size": 33,
    "exact_size": 37,
    "exact_runtime_ms": 215.997
  },
  {
    "dataset": "dataset/realworld/graph_web-spam",
    "algo": "v2",
    "n": 4767,
    "m": 37375,
    "runtime_ms": 13.725,
    "improved_solution": true,
    "initial_size": 16,
    "solution_size": 20,
    "exact_size": 21,
    "exact_runtime_ms": 24.461
  },
  {
    "dataset": "dataset/realworld/graph_web-it-2004",
    "algo": "v2",
    "n": 509338,
    "m": 7178413,
    "runtime_ms": 920.031,
    "improved_solution": false,
    "initial_size": 432,
    "solution_size": 432,
    "exact_size": 432,
    "exact_runtime_ms": 18.871
  },
  {
    "dataset": "dataset/realworld/graph_ca-CondMat",
    "algo": "v2",
    "n": 21363,
    "m": 91286,
    "runtime_ms": 18.966,
    "improved_solution": false,
    "initial_size": 26,
    "solution_size": 26,
    "exact_size": 26,
    "exact_runtime_ms": 0.973
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Indiana",
    "algo": "v2",
    "n": 29732,
    "m": 1305757,
    "runtime_ms": 1182.513,
    "improved_solution": true,
    "initial_size": 35,
    "solution_size": 47,
    "exact_size": 51,
    "exact_runtime_ms": 1482.602
  },
  {
    "dataset": "dataset/realworld/graph_scc_fb-forum",
    "algo": "v2",
    "n": 488,
    "m": 71011,
    "runtime_ms": 20.509,
    "improved_solution": false,
    "initial_size": 265,
    "solution_size": 265,
    "exact_size": 266,
    "exact_runtime_ms": 170.688
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Berkeley13",
    "algo": "v2",
    "n": 22900,
    "m": 852419,
    "runtime_ms": 656.955,
    "improved_solution": true,
    "initial_size": 34,
    "solution_size": 42,
    "exact_size": 47,
    "exact_runtime_ms": 681.528
  },
  {
    "dataset": "dataset/realworld/graph_web-webbase-2001",
    "algo": "v2",
    "n": 16062,
    "m": 25593,
    "runtime_ms": 3.258,
    "improved_solution": false,
    "initial_size": 33,
    "solution_size": 33,
    "exact_size": 33,
    "exact_runtime_ms": 0.281
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_tlot",
    "algo": "v2",
    "n": 13,
    "m": 8,
    "runtime_ms": 0.012,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 3,
    "exact_runtime_ms": 0.005
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_occupywallstnyc",
    "algo": "v2",
    "n": 127,
    "m": 931,
    "runtime_ms": 0.144,
    "improved_solution": false,
    "initial_size": 18,
    "solution_size": 18,
    "exact_size": 19,
    "exact_runtime_ms": 0.074
  },
  {
    "dataset": "dataset/realworld/graph_soc-flixster",
    "algo": "v2",
    "n": 2523386,
    "m": 7918801,
    "runtime_ms": 133565.986,
    "improved_solution": false,
    "initial_size": 31,
    "solution_size": 31,
    "exact_size": 38,
    "exact_runtime_ms": 1874.024
  },
  {
    "dataset": "dataset/realworld/graph_socfb-uci-uni",
    "algo": "v2",
    "n": 58790782,
    "m": 92208195,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_web-uk-2005",
    "algo": "v2",
    "n": 129632,
    "m": 11744049,
    "runtime_ms": 201.896,
    "improved_solution": false,
    "initial_size": 500,
    "solution_size": 500,
    "exact_size": 500,
    "exact_runtime_ms": 410.685
  },
  {
    "dataset": "dataset/realworld/graph_soc-wiki-Vote",
    "algo": "v2",
    "n": 889,
    "m": 2914,
    "runtime_ms": 1.527,
    "improved_solution": true,
    "initial_size": 6,
    "solution_size": 7,
    "exact_size": 8,
    "exact_runtime_ms": 0.302
  },
  {
    "dataset": "dataset/realworld/graph_ca-netscience",
    "algo": "v2",
    "n": 379,
    "m": 914,
    "runtime_ms": 0.119,
    "improved_solution": false,
    "initial_size": 9,
    "solution_size": 9,
    "exact_size": 9,
    "exact_runtime_ms": 0.035
  },
  {
    "dataset": "dataset/realworld/graph_soc-gowalla",
    "algo": "v2",
    "n": 196591,
    "m": 950327,
    "runtime_ms": 2846.159,
    "improved_solution": true,
    "initial_size": 16,
    "solution_size": 29,
    "exact_size": 30,
    "exact_runtime_ms": 139.82
  },
  {
    "dataset": "dataset/realworld/graph_rt-retweet",
    "algo": "v2",
    "n": 96,
    "m": 117,
    "runtime_ms": 0.036,
    "improved_solution": false,
    "initial_size": 4,
    "solution_size": 4,
    "exact_size": 4,
    "exact_runtime_ms": 0.012
  },
  {
    "dataset": "dataset/realworld/graph_ia-infect-hyper",
    "algo": "v2",
    "n": 113,
    "m": 2196,
    "runtime_ms": 1.041,
    "improved_solution": false,
    "initial_size": 15,
    "solution_size": 15,
    "exact_size": 19,
    "exact_runtime_ms": 1.083
  },
  {
    "dataset": "dataset/realworld/graph_socfb-B-anon",
    "algo": "v2",
    "n": 2937612,
    "m": 20959854,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_inf-road-usa",
    "algo": "v2",
    "n": 23947347,
    "m": 28854312,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_soc-orkut",
    "algo": "v2",
    "n": 2997166,
    "m": 106349209,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_inf-roadNet-CA",
    "algo": "v2",
    "n": 1957027,
    "m": 2760388,
    "runtime_ms": null,
    "improved_solution": false
  }
]
