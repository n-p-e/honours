[
  {
    "dataset": "dataset/realworld/graph_scc_rt_qatif",
    "algo": "v3",
    "n": 14,
    "m": 11,
    "runtime_ms": 0.012,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 3,
    "exact_runtime_ms": 0.005
  },
  {
    "dataset": "dataset/realworld/graph_ia-enron-only",
    "algo": "v3",
    "n": 143,
    "m": 623,
    "runtime_ms": 0.67,
    "improved_solution": false,
    "initial_size": 8,
    "solution_size": 8,
    "exact_size": 10,
    "exact_runtime_ms": 0.067
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_lolgop",
    "algo": "v3",
    "n": 273,
    "m": 4510,
    "runtime_ms": 1.196,
    "improved_solution": false,
    "initial_size": 42,
    "solution_size": 42,
    "exact_size": 43,
    "exact_runtime_ms": 0.394
  },
  {
    "dataset": "dataset/realworld/graph_ia-infect-dublin",
    "algo": "v3",
    "n": 410,
    "m": 2765,
    "runtime_ms": 1.848,
    "improved_solution": false,
    "initial_size": 16,
    "solution_size": 16,
    "exact_size": 17,
    "exact_runtime_ms": 0.152
  },
  {
    "dataset": "dataset/realworld/graph_ca-GrQc",
    "algo": "v3",
    "n": 4158,
    "m": 13422,
    "runtime_ms": 1.208,
    "improved_solution": false,
    "initial_size": 44,
    "solution_size": 44,
    "exact_size": 44,
    "exact_runtime_ms": 0.206
  },
  {
    "dataset": "dataset/realworld/graph_ca-HepPh",
    "algo": "v3",
    "n": 11204,
    "m": 117619,
    "runtime_ms": 14.497,
    "improved_solution": false,
    "initial_size": 239,
    "solution_size": 239,
    "exact_size": 239,
    "exact_runtime_ms": 2.131
  },
  {
    "dataset": "dataset/realworld/graph_ia-enron-large",
    "algo": "v3",
    "n": 33696,
    "m": 180811,
    "runtime_ms": 1474.234,
    "improved_solution": true,
    "initial_size": 16,
    "solution_size": 18,
    "exact_size": 22,
    "exact_runtime_ms": 36.58
  },
  {
    "dataset": "dataset/realworld/graph_tech-p2p-gnutella",
    "algo": "v3",
    "n": 62561,
    "m": 147878,
    "runtime_ms": 1771.443,
    "improved_solution": true,
    "initial_size": 2,
    "solution_size": 4,
    "exact_size": 5,
    "exact_runtime_ms": 12.737
  },
  {
    "dataset": "dataset/realworld/graph_rec-amazon",
    "algo": "v3",
    "n": 91813,
    "m": 125704,
    "runtime_ms": 2681.685,
    "improved_solution": true,
    "initial_size": 4,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 2.993
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_mittromney",
    "algo": "v3",
    "n": 102,
    "m": 108,
    "runtime_ms": 0.062,
    "improved_solution": false,
    "initial_size": 5,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.014
  },
  {
    "dataset": "dataset/realworld/graph_web-BerkStan",
    "algo": "v3",
    "n": 12305,
    "m": 19500,
    "runtime_ms": 2.162,
    "improved_solution": false,
    "initial_size": 29,
    "solution_size": 29,
    "exact_size": 29,
    "exact_runtime_ms": 0.287
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_occupy",
    "algo": "v3",
    "n": 55,
    "m": 60,
    "runtime_ms": 0.033,
    "improved_solution": false,
    "initial_size": 5,
    "solution_size": 5,
    "exact_size": 5,
    "exact_runtime_ms": 0.02
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_damascus",
    "algo": "v3",
    "n": 34,
    "m": 41,
    "runtime_ms": 0.052,
    "improved_solution": false,
    "initial_size": 5,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.008
  },
  {
    "dataset": "dataset/realworld/graph_scc_infect-hyper",
    "algo": "v3",
    "n": 113,
    "m": 6222,
    "runtime_ms": 0.665,
    "improved_solution": false,
    "initial_size": 106,
    "solution_size": 106,
    "exact_size": 106,
    "exact_runtime_ms": 0.412
  },
  {
    "dataset": "dataset/realworld/graph_soc-epinions",
    "algo": "v3",
    "n": 26588,
    "m": 100120,
    "runtime_ms": 718.648,
    "improved_solution": true,
    "initial_size": 12,
    "solution_size": 16,
    "exact_size": 18,
    "exact_runtime_ms": 15.568
  },
  {
    "dataset": "dataset/realworld/graph_sc-nasasrb",
    "algo": "v3",
    "n": 54870,
    "m": 1311227,
    "runtime_ms": 2879.952,
    "improved_solution": false,
    "initial_size": 24,
    "solution_size": 24,
    "exact_size": 24,
    "exact_runtime_ms": 243.045
  },
  {
    "dataset": "dataset/realworld/graph_tech-as-caida2007",
    "algo": "v3",
    "n": 26475,
    "m": 53381,
    "runtime_ms": 69.993,
    "improved_solution": false,
    "initial_size": 16,
    "solution_size": 16,
    "exact_size": 17,
    "exact_runtime_ms": 1.767
  },
  {
    "dataset": "dataset/realworld/graph_soc-slashdot",
    "algo": "v3",
    "n": 70068,
    "m": 358647,
    "runtime_ms": 3596.914,
    "improved_solution": true,
    "initial_size": 25,
    "solution_size": 26,
    "exact_size": 31,
    "exact_runtime_ms": 221.861
  },
  {
    "dataset": "dataset/realworld/graph_web-google",
    "algo": "v3",
    "n": 1299,
    "m": 2773,
    "runtime_ms": 0.29,
    "improved_solution": false,
    "initial_size": 18,
    "solution_size": 18,
    "exact_size": 19,
    "exact_runtime_ms": 0.062
  },
  {
    "dataset": "dataset/realworld/graph_scc_retweet-crawl",
    "algo": "v3",
    "n": 17151,
    "m": 24015,
    "runtime_ms": 6.726,
    "improved_solution": false,
    "initial_size": 20,
    "solution_size": 20,
    "exact_size": 21,
    "exact_runtime_ms": 0.375
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_israel",
    "algo": "v3",
    "n": 22,
    "m": 12,
    "runtime_ms": 0.013,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 3,
    "exact_runtime_ms": 0.015
  },
  {
    "dataset": "dataset/realworld/graph_ca-CSphd",
    "algo": "v3",
    "n": 1882,
    "m": 1740,
    "runtime_ms": 2.868,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 4,
    "exact_runtime_ms": 0.043
  },
  {
    "dataset": "dataset/realworld/graph_soc-douban",
    "algo": "v3",
    "n": 154908,
    "m": 327162,
    "runtime_ms": 3212.484,
    "improved_solution": true,
    "initial_size": 5,
    "solution_size": 11,
    "exact_size": 12,
    "exact_runtime_ms": 25.199
  },
  {
    "dataset": "dataset/realworld/graph_tech-RL-caida",
    "algo": "v3",
    "n": 190914,
    "m": 607610,
    "runtime_ms": 10904.857,
    "improved_solution": true,
    "initial_size": 6,
    "solution_size": 17,
    "exact_size": 20,
    "exact_runtime_ms": 27.022
  },
  {
    "dataset": "dataset/realworld/graph_ca-hollywood-2009",
    "algo": "v3",
    "n": 1069126,
    "m": 56306653,
    "runtime_ms": 76034.996,
    "improved_solution": false,
    "initial_size": 2209,
    "solution_size": 2209,
    "exact_size": 2209,
    "exact_runtime_ms": 320.742
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_obama",
    "algo": "v3",
    "n": 8,
    "m": 4,
    "runtime_ms": 0.017,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 2,
    "exact_runtime_ms": 0.015
  },
  {
    "dataset": "dataset/realworld/graph_socfb-UCSB37",
    "algo": "v3",
    "n": 14917,
    "m": 482215,
    "runtime_ms": 13116.368,
    "improved_solution": true,
    "initial_size": 52,
    "solution_size": 53,
    "exact_size": 59,
    "exact_runtime_ms": 52.908
  },
  {
    "dataset": "dataset/realworld/graph_sc-shipsec5",
    "algo": "v3",
    "n": 179104,
    "m": 2200076,
    "runtime_ms": 9571.743,
    "improved_solution": false,
    "initial_size": 24,
    "solution_size": 24,
    "exact_size": 24,
    "exact_runtime_ms": 92.7
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_tcot",
    "algo": "v3",
    "n": 26,
    "m": 18,
    "runtime_ms": 0.018,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 4,
    "exact_runtime_ms": 0.007
  },
  {
    "dataset": "dataset/realworld/graph_soc-youtube",
    "algo": "v3",
    "n": 495957,
    "m": 1936748,
    "runtime_ms": 131322.538,
    "improved_solution": true,
    "initial_size": 13,
    "solution_size": 16,
    "exact_size": 20,
    "exact_runtime_ms": 342.694
  },
  {
    "dataset": "dataset/realworld/graph_web-arabic-2005",
    "algo": "v3",
    "n": 163598,
    "m": 1747269,
    "runtime_ms": 51.794,
    "improved_solution": false,
    "initial_size": 102,
    "solution_size": 102,
    "exact_size": 102,
    "exact_runtime_ms": 4.556
  },
  {
    "dataset": "dataset/realworld/graph_ca-dblp-2012",
    "algo": "v3",
    "n": 317080,
    "m": 1049866,
    "runtime_ms": 171.686,
    "improved_solution": false,
    "initial_size": 114,
    "solution_size": 114,
    "exact_size": 114,
    "exact_runtime_ms": 8.048
  },
  {
    "dataset": "dataset/realworld/graph_web-polblogs",
    "algo": "v3",
    "n": 643,
    "m": 2280,
    "runtime_ms": 2.375,
    "improved_solution": false,
    "initial_size": 9,
    "solution_size": 9,
    "exact_size": 12,
    "exact_runtime_ms": 0.162
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_alwefaq",
    "algo": "v3",
    "n": 72,
    "m": 355,
    "runtime_ms": 0.079,
    "improved_solution": false,
    "initial_size": 16,
    "solution_size": 16,
    "exact_size": 17,
    "exact_runtime_ms": 0.04
  },
  {
    "dataset": "dataset/realworld/graph_tech-routers-rf",
    "algo": "v3",
    "n": 2113,
    "m": 6632,
    "runtime_ms": 4.698,
    "improved_solution": false,
    "initial_size": 16,
    "solution_size": 16,
    "exact_size": 17,
    "exact_runtime_ms": 0.128
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_gop",
    "algo": "v3",
    "n": 13,
    "m": 7,
    "runtime_ms": 0.011,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 3,
    "exact_runtime_ms": 0.013
  },
  {
    "dataset": "dataset/realworld/graph_ia-email-univ",
    "algo": "v3",
    "n": 1133,
    "m": 5451,
    "runtime_ms": 6.627,
    "improved_solution": false,
    "initial_size": 12,
    "solution_size": 12,
    "exact_size": 12,
    "exact_runtime_ms": 0.109
  },
  {
    "dataset": "dataset/realworld/graph_sc-pkustk11",
    "algo": "v3",
    "n": 87804,
    "m": 2565054,
    "runtime_ms": 7335.084,
    "improved_solution": true,
    "initial_size": 24,
    "solution_size": 36,
    "exact_size": 36,
    "exact_runtime_ms": 651.015
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_assad",
    "algo": "v3",
    "n": 34,
    "m": 96,
    "runtime_ms": 0.044,
    "improved_solution": false,
    "initial_size": 8,
    "solution_size": 8,
    "exact_size": 9,
    "exact_runtime_ms": 0.014
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Texas84",
    "algo": "v3",
    "n": 36364,
    "m": 1590651,
    "runtime_ms": 155578.589,
    "improved_solution": true,
    "initial_size": 48,
    "solution_size": 51,
    "exact_size": 55,
    "exact_runtime_ms": 1775.674
  },
  {
    "dataset": "dataset/realworld/graph_ca-AstroPh",
    "algo": "v3",
    "n": 17903,
    "m": 196972,
    "runtime_ms": 602.378,
    "improved_solution": false,
    "initial_size": 57,
    "solution_size": 57,
    "exact_size": 57,
    "exact_runtime_ms": 2.253
  },
  {
    "dataset": "dataset/realworld/graph_soc-twitter-follows",
    "algo": "v3",
    "n": 404719,
    "m": 713319,
    "runtime_ms": 170862.876,
    "improved_solution": true,
    "initial_size": 2,
    "solution_size": 6,
    "exact_size": 8,
    "exact_runtime_ms": 52.541
  },
  {
    "dataset": "dataset/realworld/graph_soc-delicious",
    "algo": "v3",
    "n": 536108,
    "m": 1365961,
    "runtime_ms": 22084.239,
    "improved_solution": true,
    "initial_size": 16,
    "solution_size": 21,
    "exact_size": 23,
    "exact_runtime_ms": 51.344
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Wisconsin87",
    "algo": "v3",
    "n": 23831,
    "m": 835946,
    "runtime_ms": 44873.262,
    "improved_solution": true,
    "initial_size": 34,
    "solution_size": 37,
    "exact_size": 42,
    "exact_runtime_ms": 518.68
  },
  {
    "dataset": "dataset/realworld/graph_tech-WHOIS",
    "algo": "v3",
    "n": 7476,
    "m": 56943,
    "runtime_ms": 139.818,
    "improved_solution": true,
    "initial_size": 55,
    "solution_size": 58,
    "exact_size": 64,
    "exact_runtime_ms": 328.057
  },
  {
    "dataset": "dataset/realworld/graph_soc-karate",
    "algo": "v3",
    "n": 34,
    "m": 78,
    "runtime_ms": 0.057,
    "improved_solution": false,
    "initial_size": 5,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.013
  },
  {
    "dataset": "dataset/realworld/graph_bio-dmela",
    "algo": "v3",
    "n": 7393,
    "m": 25569,
    "runtime_ms": 78.821,
    "improved_solution": true,
    "initial_size": 5,
    "solution_size": 7,
    "exact_size": 8,
    "exact_runtime_ms": 2.052
  },
  {
    "dataset": "dataset/realworld/graph_tech-internet-as",
    "algo": "v3",
    "n": 40164,
    "m": 85123,
    "runtime_ms": 262.93,
    "improved_solution": true,
    "initial_size": 14,
    "solution_size": 16,
    "exact_size": 18,
    "exact_runtime_ms": 2.874
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_lebanon",
    "algo": "v3",
    "n": 10,
    "m": 5,
    "runtime_ms": 0.009,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 2,
    "exact_runtime_ms": 0.01
  },
  {
    "dataset": "dataset/realworld/graph_scc_fb-messages",
    "algo": "v3",
    "n": 1303,
    "m": 531893,
    "runtime_ms": 559.629,
    "improved_solution": false,
    "initial_size": 707,
    "solution_size": 707,
    "exact_size": 708,
    "exact_runtime_ms": 36.914
  },
  {
    "dataset": "dataset/realworld/graph_inf-roadNet-PA",
    "algo": "v3",
    "n": 1087562,
    "m": 1541514,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_bio-yeast",
    "algo": "v3",
    "n": 1458,
    "m": 1948,
    "runtime_ms": 0.872,
    "improved_solution": false,
    "initial_size": 6,
    "solution_size": 6,
    "exact_size": 6,
    "exact_runtime_ms": 0.052
  },
  {
    "dataset": "dataset/realworld/graph_scc_retweet",
    "algo": "v3",
    "n": 1206,
    "m": 65990,
    "runtime_ms": 89.756,
    "improved_solution": false,
    "initial_size": 164,
    "solution_size": 164,
    "exact_size": 166,
    "exact_runtime_ms": 35.777
  },
  {
    "dataset": "dataset/realworld/graph_soc-brightkite",
    "algo": "v3",
    "n": 56739,
    "m": 212945,
    "runtime_ms": 387.773,
    "improved_solution": false,
    "initial_size": 37,
    "solution_size": 37,
    "exact_size": 44,
    "exact_runtime_ms": 7.41
  },
  {
    "dataset": "dataset/realworld/graph_soc-LiveMocha",
    "algo": "v3",
    "n": 104103,
    "m": 2193083,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_soc-FourSquare",
    "algo": "v3",
    "n": 639014,
    "m": 3214986,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_uae",
    "algo": "v3",
    "n": 18,
    "m": 12,
    "runtime_ms": 0.012,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 3,
    "exact_runtime_ms": 0.005
  },
  {
    "dataset": "dataset/realworld/graph_ca-MathSciNet",
    "algo": "v3",
    "n": 332689,
    "m": 820644,
    "runtime_ms": 1793.865,
    "improved_solution": false,
    "initial_size": 25,
    "solution_size": 25,
    "exact_size": 25,
    "exact_runtime_ms": 16.334
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_ksa",
    "algo": "v3",
    "n": 21,
    "m": 23,
    "runtime_ms": 0.011,
    "improved_solution": false,
    "initial_size": 6,
    "solution_size": 6,
    "exact_size": 6,
    "exact_runtime_ms": 0.005
  },
  {
    "dataset": "dataset/realworld/graph_tech-as-skitter",
    "algo": "v3",
    "n": 1694616,
    "m": 11094209,
    "runtime_ms": 117568.99,
    "improved_solution": true,
    "initial_size": 57,
    "solution_size": 67,
    "exact_size": 69,
    "exact_runtime_ms": 495.73
  },
  {
    "dataset": "dataset/realworld/graph_sc-pwtk",
    "algo": "v3",
    "n": 217891,
    "m": 5653221,
    "runtime_ms": 27791.848,
    "improved_solution": false,
    "initial_size": 24,
    "solution_size": 24,
    "exact_size": 24,
    "exact_runtime_ms": 929.735
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_dash",
    "algo": "v3",
    "n": 31,
    "m": 39,
    "runtime_ms": 0.016,
    "improved_solution": false,
    "initial_size": 6,
    "solution_size": 6,
    "exact_size": 6,
    "exact_runtime_ms": 0.008
  },
  {
    "dataset": "dataset/realworld/graph_socfb-UCLA",
    "algo": "v3",
    "n": 20453,
    "m": 747604,
    "runtime_ms": 32885.877,
    "improved_solution": true,
    "initial_size": 50,
    "solution_size": 51,
    "exact_size": 55,
    "exact_runtime_ms": 379.254
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_p2",
    "algo": "v3",
    "n": 26,
    "m": 15,
    "runtime_ms": 0.017,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 3,
    "exact_runtime_ms": 0.016
  },
  {
    "dataset": "dataset/realworld/graph_web-wikipedia2009",
    "algo": "v3",
    "n": 1864433,
    "m": 4507315,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_socfb-UIllinois",
    "algo": "v3",
    "n": 30795,
    "m": 1264421,
    "runtime_ms": 100685.914,
    "improved_solution": true,
    "initial_size": 18,
    "solution_size": 57,
    "exact_size": 63,
    "exact_runtime_ms": 1198.733
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_http",
    "algo": "v3",
    "n": 5,
    "m": 6,
    "runtime_ms": 0.012,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 4,
    "exact_runtime_ms": 0.004
  },
  {
    "dataset": "dataset/realworld/graph_bio-diseasome",
    "algo": "v3",
    "n": 516,
    "m": 1188,
    "runtime_ms": 0.225,
    "improved_solution": false,
    "initial_size": 11,
    "solution_size": 11,
    "exact_size": 11,
    "exact_runtime_ms": 0.032
  },
  {
    "dataset": "dataset/realworld/graph_soc-dolphins",
    "algo": "v3",
    "n": 62,
    "m": 159,
    "runtime_ms": 0.123,
    "improved_solution": false,
    "initial_size": 5,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.014
  },
  {
    "dataset": "dataset/realworld/graph_soc-lastfm",
    "algo": "v3",
    "n": 1191805,
    "m": 4519330,
    "runtime_ms": 262626.248,
    "improved_solution": true,
    "initial_size": 13,
    "solution_size": 14,
    "exact_size": 18,
    "exact_runtime_ms": 14664.341
  },
  {
    "dataset": "dataset/realworld/graph_web-indochina-2004",
    "algo": "v3",
    "n": 11358,
    "m": 47606,
    "runtime_ms": 3.733,
    "improved_solution": false,
    "initial_size": 50,
    "solution_size": 50,
    "exact_size": 50,
    "exact_runtime_ms": 0.37
  },
  {
    "dataset": "dataset/realworld/graph_socfb-UConn",
    "algo": "v3",
    "n": 17206,
    "m": 604867,
    "runtime_ms": 20962.561,
    "improved_solution": false,
    "initial_size": 50,
    "solution_size": 50,
    "exact_size": 53,
    "exact_runtime_ms": 178.016
  },
  {
    "dataset": "dataset/realworld/graph_ca-Erdos992",
    "algo": "v3",
    "n": 5094,
    "m": 7515,
    "runtime_ms": 3.026,
    "improved_solution": false,
    "initial_size": 8,
    "solution_size": 8,
    "exact_size": 8,
    "exact_runtime_ms": 0.095
  },
  {
    "dataset": "dataset/realworld/graph_socfb-UF",
    "algo": "v3",
    "n": 35111,
    "m": 1465654,
    "runtime_ms": 131812.02,
    "improved_solution": true,
    "initial_size": 47,
    "solution_size": 55,
    "exact_size": 60,
    "exact_runtime_ms": 1575.954
  },
  {
    "dataset": "dataset/realworld/graph_sc-ldoor",
    "algo": "v3",
    "n": 909537,
    "m": 20770807,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_scc_enron-only",
    "algo": "v3",
    "n": 146,
    "m": 9828,
    "runtime_ms": 2.103,
    "improved_solution": false,
    "initial_size": 120,
    "solution_size": 120,
    "exact_size": 121,
    "exact_runtime_ms": 0.707
  },
  {
    "dataset": "dataset/realworld/graph_ca-coauthors-dblp",
    "algo": "v3",
    "n": 540486,
    "m": 15245729,
    "runtime_ms": 3310.964,
    "improved_solution": false,
    "initial_size": 337,
    "solution_size": 337,
    "exact_size": 337,
    "exact_runtime_ms": 39.347
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_barackobama",
    "algo": "v3",
    "n": 80,
    "m": 226,
    "runtime_ms": 0.082,
    "improved_solution": false,
    "initial_size": 10,
    "solution_size": 10,
    "exact_size": 11,
    "exact_runtime_ms": 0.047
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Duke14",
    "algo": "v3",
    "n": 9885,
    "m": 506437,
    "runtime_ms": 25657.519,
    "improved_solution": true,
    "initial_size": 29,
    "solution_size": 34,
    "exact_size": 38,
    "exact_runtime_ms": 5656.781
  },
  {
    "dataset": "dataset/realworld/graph_inf-power",
    "algo": "v3",
    "n": 4941,
    "m": 6594,
    "runtime_ms": 3.703,
    "improved_solution": false,
    "initial_size": 6,
    "solution_size": 6,
    "exact_size": 6,
    "exact_runtime_ms": 0.166
  },
  {
    "dataset": "dataset/realworld/graph_soc-livejournal",
    "algo": "v3",
    "n": 4033137,
    "m": 27933062,
    "runtime_ms": 44846.066,
    "improved_solution": false,
    "initial_size": 214,
    "solution_size": 214,
    "exact_size": 214,
    "exact_runtime_ms": 603.741
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Stanford3",
    "algo": "v3",
    "n": 11586,
    "m": 568309,
    "runtime_ms": 34842.584,
    "improved_solution": true,
    "initial_size": 21,
    "solution_size": 51,
    "exact_size": 59,
    "exact_runtime_ms": 594.04
  },
  {
    "dataset": "dataset/realworld/graph_scc_reality",
    "algo": "v3",
    "n": 6809,
    "m": 4714485,
    "runtime_ms": 7859.148,
    "improved_solution": false,
    "initial_size": 1236,
    "solution_size": 1236,
    "exact_size": 1236,
    "exact_runtime_ms": 257.487
  },
  {
    "dataset": "dataset/realworld/graph_scc_twitter-copen",
    "algo": "v3",
    "n": 2623,
    "m": 473614,
    "runtime_ms": 537.634,
    "improved_solution": false,
    "initial_size": 576,
    "solution_size": 576,
    "exact_size": 581,
    "exact_runtime_ms": 504.634
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Penn94",
    "algo": "v3",
    "n": 41536,
    "m": 1362220,
    "runtime_ms": 99782.403,
    "improved_solution": true,
    "initial_size": 34,
    "solution_size": 44,
    "exact_size": 50,
    "exact_runtime_ms": 1069.708
  },
  {
    "dataset": "dataset/realworld/graph_bio-celegans",
    "algo": "v3",
    "n": 453,
    "m": 2025,
    "runtime_ms": 4.173,
    "improved_solution": true,
    "initial_size": 8,
    "solution_size": 9,
    "exact_size": 10,
    "exact_runtime_ms": 0.19
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_justinbieber",
    "algo": "v3",
    "n": 62,
    "m": 442,
    "runtime_ms": 0.13,
    "improved_solution": false,
    "initial_size": 17,
    "solution_size": 17,
    "exact_size": 18,
    "exact_runtime_ms": 0.046
  },
  {
    "dataset": "dataset/realworld/graph_rt-retweet-crawl",
    "algo": "v3",
    "n": 1112702,
    "m": 2278852,
    "runtime_ms": 124631.19,
    "improved_solution": true,
    "initial_size": 9,
    "solution_size": 13,
    "exact_size": 14,
    "exact_runtime_ms": 178.23
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_oman",
    "algo": "v3",
    "n": 16,
    "m": 13,
    "runtime_ms": 0.019,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 4,
    "exact_runtime_ms": 0.005
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_saudi",
    "algo": "v3",
    "n": 28,
    "m": 91,
    "runtime_ms": 0.045,
    "improved_solution": false,
    "initial_size": 8,
    "solution_size": 8,
    "exact_size": 9,
    "exact_runtime_ms": 0.034
  },
  {
    "dataset": "dataset/realworld/graph_sc-pkustk13",
    "algo": "v3",
    "n": 94893,
    "m": 3260967,
    "runtime_ms": 15129.044,
    "improved_solution": true,
    "initial_size": 33,
    "solution_size": 36,
    "exact_size": 36,
    "exact_runtime_ms": 1036.98
  },
  {
    "dataset": "dataset/realworld/graph_socfb-CMU",
    "algo": "v3",
    "n": 6621,
    "m": 249959,
    "runtime_ms": 7663.488,
    "improved_solution": true,
    "initial_size": 35,
    "solution_size": 45,
    "exact_size": 47,
    "exact_runtime_ms": 153.438
  },
  {
    "dataset": "dataset/realworld/graph_sc-shipsec1",
    "algo": "v3",
    "n": 140385,
    "m": 1707759,
    "runtime_ms": 7349.889,
    "improved_solution": false,
    "initial_size": 24,
    "solution_size": 24,
    "exact_size": 24,
    "exact_runtime_ms": 58.523
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_libya",
    "algo": "v3",
    "n": 27,
    "m": 26,
    "runtime_ms": 0.041,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 4,
    "exact_runtime_ms": 0.009
  },
  {
    "dataset": "dataset/realworld/graph_scc_infect-dublin",
    "algo": "v3",
    "n": 10972,
    "m": 175573,
    "runtime_ms": 23.735,
    "improved_solution": false,
    "initial_size": 84,
    "solution_size": 84,
    "exact_size": 84,
    "exact_runtime_ms": 1.832
  },
  {
    "dataset": "dataset/realworld/graph_ca-dblp-2010",
    "algo": "v3",
    "n": 226413,
    "m": 716460,
    "runtime_ms": 134.926,
    "improved_solution": false,
    "initial_size": 75,
    "solution_size": 75,
    "exact_size": 75,
    "exact_runtime_ms": 5.713
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_voteonedirection",
    "algo": "v3",
    "n": 7,
    "m": 5,
    "runtime_ms": 0.01,
    "improved_solution": false,
    "initial_size": 3,
    "solution_size": 3,
    "exact_size": 3,
    "exact_runtime_ms": 0.005
  },
  {
    "dataset": "dataset/realworld/graph_ia-wiki-Talk",
    "algo": "v3",
    "n": 92117,
    "m": 360767,
    "runtime_ms": 11204.171,
    "improved_solution": true,
    "initial_size": 11,
    "solution_size": 14,
    "exact_size": 18,
    "exact_runtime_ms": 1748.179
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_onedirection",
    "algo": "v3",
    "n": 35,
    "m": 368,
    "runtime_ms": 0.137,
    "improved_solution": false,
    "initial_size": 27,
    "solution_size": 27,
    "exact_size": 27,
    "exact_runtime_ms": 0.019
  },
  {
    "dataset": "dataset/realworld/graph_soc-pokec",
    "algo": "v3",
    "n": 1632803,
    "m": 22301964,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_socfb-OR",
    "algo": "v3",
    "n": 63392,
    "m": 816886,
    "runtime_ms": 15316.622,
    "improved_solution": true,
    "initial_size": 25,
    "solution_size": 30,
    "exact_size": 33,
    "exact_runtime_ms": 294.127
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_bahrain",
    "algo": "v3",
    "n": 72,
    "m": 129,
    "runtime_ms": 0.055,
    "improved_solution": false,
    "initial_size": 8,
    "solution_size": 8,
    "exact_size": 9,
    "exact_runtime_ms": 0.015
  },
  {
    "dataset": "dataset/realworld/graph_socfb-A-anon",
    "algo": "v3",
    "n": 3097165,
    "m": 23667394,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_gmanews",
    "algo": "v3",
    "n": 135,
    "m": 1078,
    "runtime_ms": 0.253,
    "improved_solution": false,
    "initial_size": 22,
    "solution_size": 22,
    "exact_size": 22,
    "exact_runtime_ms": 0.17
  },
  {
    "dataset": "dataset/realworld/graph_rt-twitter-copen",
    "algo": "v3",
    "n": 761,
    "m": 1029,
    "runtime_ms": 0.935,
    "improved_solution": false,
    "initial_size": 4,
    "solution_size": 4,
    "exact_size": 5,
    "exact_runtime_ms": 0.055
  },
  {
    "dataset": "dataset/realworld/graph_ia-fb-messages",
    "algo": "v3",
    "n": 1266,
    "m": 6451,
    "runtime_ms": 35.901,
    "improved_solution": true,
    "initial_size": 4,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.914
  },
  {
    "dataset": "dataset/realworld/graph_web-edu",
    "algo": "v3",
    "n": 3031,
    "m": 6474,
    "runtime_ms": 0.686,
    "improved_solution": false,
    "initial_size": 30,
    "solution_size": 30,
    "exact_size": 30,
    "exact_runtime_ms": 0.091
  },
  {
    "dataset": "dataset/realworld/graph_sc-msdoor",
    "algo": "v3",
    "n": 404785,
    "m": 9378650,
    "runtime_ms": 157239.822,
    "improved_solution": false,
    "initial_size": 21,
    "solution_size": 21,
    "exact_size": 21,
    "exact_runtime_ms": 6088.602
  },
  {
    "dataset": "dataset/realworld/graph_web-sk-2005",
    "algo": "v3",
    "n": 121422,
    "m": 334419,
    "runtime_ms": 38.383,
    "improved_solution": false,
    "initial_size": 82,
    "solution_size": 82,
    "exact_size": 82,
    "exact_runtime_ms": 4.756
  },
  {
    "dataset": "dataset/realworld/graph_ca-citeseer",
    "algo": "v3",
    "n": 227320,
    "m": 814134,
    "runtime_ms": 141.994,
    "improved_solution": false,
    "initial_size": 87,
    "solution_size": 87,
    "exact_size": 87,
    "exact_runtime_ms": 10.752
  },
  {
    "dataset": "dataset/realworld/graph_ia-reality",
    "algo": "v3",
    "n": 6809,
    "m": 7680,
    "runtime_ms": 4.375,
    "improved_solution": true,
    "initial_size": 4,
    "solution_size": 5,
    "exact_size": 6,
    "exact_runtime_ms": 0.148
  },
  {
    "dataset": "dataset/realworld/graph_ia-email-EU",
    "algo": "v3",
    "n": 32430,
    "m": 54397,
    "runtime_ms": 117.538,
    "improved_solution": true,
    "initial_size": 11,
    "solution_size": 12,
    "exact_size": 15,
    "exact_runtime_ms": 3.515
  },
  {
    "dataset": "dataset/realworld/graph_soc-flixster",
    "algo": "v3",
    "n": 2523386,
    "m": 7918801,
    "runtime_ms": 275537.228,
    "improved_solution": false,
    "initial_size": 31,
    "solution_size": 31,
    "exact_size": 38,
    "exact_runtime_ms": 1821.878
  },
  {
    "dataset": "dataset/realworld/graph_socfb-uci-uni",
    "algo": "v3",
    "n": 58790782,
    "m": 92208195,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_web-spam",
    "algo": "v3",
    "n": 4767,
    "m": 37375,
    "runtime_ms": 294.475,
    "improved_solution": true,
    "initial_size": 16,
    "solution_size": 20,
    "exact_size": 21,
    "exact_runtime_ms": 23.395
  },
  {
    "dataset": "dataset/realworld/graph_socfb-MIT",
    "algo": "v3",
    "n": 6402,
    "m": 251230,
    "runtime_ms": 8374.744,
    "improved_solution": true,
    "initial_size": 29,
    "solution_size": 33,
    "exact_size": 37,
    "exact_runtime_ms": 203.68
  },
  {
    "dataset": "dataset/realworld/graph_ca-CondMat",
    "algo": "v3",
    "n": 21363,
    "m": 91286,
    "runtime_ms": 55.992,
    "improved_solution": false,
    "initial_size": 26,
    "solution_size": 26,
    "exact_size": 26,
    "exact_runtime_ms": 0.979
  },
  {
    "dataset": "dataset/realworld/graph_web-it-2004",
    "algo": "v3",
    "n": 509338,
    "m": 7178413,
    "runtime_ms": 784.755,
    "improved_solution": false,
    "initial_size": 432,
    "solution_size": 432,
    "exact_size": 432,
    "exact_runtime_ms": 15.233
  },
  {
    "dataset": "dataset/realworld/graph_scc_fb-forum",
    "algo": "v3",
    "n": 488,
    "m": 71011,
    "runtime_ms": 50.828,
    "improved_solution": false,
    "initial_size": 265,
    "solution_size": 265,
    "exact_size": 266,
    "exact_runtime_ms": 162.125
  },
  {
    "dataset": "dataset/realworld/graph_socfb-B-anon",
    "algo": "v3",
    "n": 2937612,
    "m": 20959854,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_web-webbase-2001",
    "algo": "v3",
    "n": 16062,
    "m": 25593,
    "runtime_ms": 3.941,
    "improved_solution": false,
    "initial_size": 33,
    "solution_size": 33,
    "exact_size": 33,
    "exact_runtime_ms": 0.276
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_tlot",
    "algo": "v3",
    "n": 13,
    "m": 8,
    "runtime_ms": 0.011,
    "improved_solution": false,
    "initial_size": 2,
    "solution_size": 2,
    "exact_size": 3,
    "exact_runtime_ms": 0.004
  },
  {
    "dataset": "dataset/realworld/graph_scc_rt_occupywallstnyc",
    "algo": "v3",
    "n": 127,
    "m": 931,
    "runtime_ms": 0.371,
    "improved_solution": false,
    "initial_size": 18,
    "solution_size": 18,
    "exact_size": 19,
    "exact_runtime_ms": 0.074
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Berkeley13",
    "algo": "v3",
    "n": 22900,
    "m": 852419,
    "runtime_ms": 57344.876,
    "improved_solution": true,
    "initial_size": 34,
    "solution_size": 42,
    "exact_size": 47,
    "exact_runtime_ms": 685.431
  },
  {
    "dataset": "dataset/realworld/graph_soc-youtube-snap",
    "algo": "v3",
    "n": 1134890,
    "m": 2987624,
    "runtime_ms": 295887.342,
    "improved_solution": true,
    "initial_size": 13,
    "solution_size": 17,
    "exact_size": 20,
    "exact_runtime_ms": 487.471
  },
  {
    "dataset": "dataset/realworld/graph_socfb-Indiana",
    "algo": "v3",
    "n": 29732,
    "m": 1305757,
    "runtime_ms": 91788.798,
    "improved_solution": true,
    "initial_size": 35,
    "solution_size": 48,
    "exact_size": 51,
    "exact_runtime_ms": 1114.713
  },
  {
    "dataset": "dataset/realworld/graph_soc-wiki-Vote",
    "algo": "v3",
    "n": 889,
    "m": 2914,
    "runtime_ms": 5.859,
    "improved_solution": false,
    "initial_size": 6,
    "solution_size": 6,
    "exact_size": 8,
    "exact_runtime_ms": 0.214
  },
  {
    "dataset": "dataset/realworld/graph_ca-netscience",
    "algo": "v3",
    "n": 379,
    "m": 914,
    "runtime_ms": 0.171,
    "improved_solution": false,
    "initial_size": 9,
    "solution_size": 9,
    "exact_size": 9,
    "exact_runtime_ms": 0.03
  },
  {
    "dataset": "dataset/realworld/graph_web-uk-2005",
    "algo": "v3",
    "n": 129632,
    "m": 11744049,
    "runtime_ms": 249.45,
    "improved_solution": false,
    "initial_size": 500,
    "solution_size": 500,
    "exact_size": 500,
    "exact_runtime_ms": 397.228
  },
  {
    "dataset": "dataset/realworld/graph_rt-retweet",
    "algo": "v3",
    "n": 96,
    "m": 117,
    "runtime_ms": 0.078,
    "improved_solution": false,
    "initial_size": 4,
    "solution_size": 4,
    "exact_size": 4,
    "exact_runtime_ms": 0.013
  },
  {
    "dataset": "dataset/realworld/graph_ia-infect-hyper",
    "algo": "v3",
    "n": 113,
    "m": 2196,
    "runtime_ms": 2.637,
    "improved_solution": false,
    "initial_size": 15,
    "solution_size": 15,
    "exact_size": 19,
    "exact_runtime_ms": 1.273
  },
  {
    "dataset": "dataset/realworld/graph_inf-road-usa",
    "algo": "v3",
    "n": 23947347,
    "m": 28854312,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_soc-gowalla",
    "algo": "v3",
    "n": 196591,
    "m": 950327,
    "runtime_ms": 22826.829,
    "improved_solution": true,
    "initial_size": 16,
    "solution_size": 29,
    "exact_size": 30,
    "exact_runtime_ms": 141.852
  },
  {
    "dataset": "dataset/realworld/graph_soc-orkut",
    "algo": "v3",
    "n": 2997166,
    "m": 106349209,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_soc-digg",
    "algo": "v3",
    "n": 770799,
    "m": 5907132,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_inf-roadNet-CA",
    "algo": "v3",
    "n": 1957027,
    "m": 2760388,
    "runtime_ms": null,
    "improved_solution": false
  },
  {
    "dataset": "dataset/realworld/graph_soc-buzznet",
    "algo": "v3",
    "n": 101163,
    "m": 2763066,
    "runtime_ms": null,
    "improved_solution": false
  }
]
